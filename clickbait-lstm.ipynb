{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUjyhhEPMKB7"
      },
      "source": [
        "Jason<br>\n",
        "2401960183<br>\n",
        "Deep Learning Final Exam No 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAr5jbaRMTP6"
      },
      "source": [
        "Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1KKYjd7wSsA",
        "outputId": "9af6a626-85e2-43c1-8bee-52dd1afeaac7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import nltk\n",
        "import string as s\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import string\n",
        "import tensorflow\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Input, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score, accuracy_score\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXI-esRyMutJ"
      },
      "source": [
        "<h1> 1. Loading and Preprocessing Data using NLP Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4fPJFA4Mcwk"
      },
      "source": [
        "Loading the clickbait.csv dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Iw2PDSj4wSsJ",
        "outputId": "fe08dee7-41a5-4536-e9b4-cd77dcf0567c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e3b5b6ba-a1d4-44d5-b825-c2b904f09938\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>clickbait</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Should I Get Bings</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Which TV Female Friend Group Do You Belong In</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The New \"Star Wars: The Force Awakens\" Trailer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This Vine Of New York On \"Celebrity Big Brothe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A Couple Did A Stunning Photo Shoot With Their...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3b5b6ba-a1d4-44d5-b825-c2b904f09938')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e3b5b6ba-a1d4-44d5-b825-c2b904f09938 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e3b5b6ba-a1d4-44d5-b825-c2b904f09938');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            headline  clickbait\n",
              "0                                 Should I Get Bings          1\n",
              "1      Which TV Female Friend Group Do You Belong In          1\n",
              "2  The New \"Star Wars: The Force Awakens\" Trailer...          1\n",
              "3  This Vine Of New York On \"Celebrity Big Brothe...          1\n",
              "4  A Couple Did A Stunning Photo Shoot With Their...          1"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv(\"./clickbait.csv\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7tbb5JswSsK",
        "outputId": "46d79801-db1b-4067-96e3-480bdf95b720"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(32000, 2)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oObQuX4Mi0B"
      },
      "source": [
        "Get the features (X) and the labels (y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SFDGzabxwSsK"
      },
      "outputs": [],
      "source": [
        "X = data['headline']\n",
        "y = data['clickbait']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgbHu8WYwSsL",
        "outputId": "995ecb19-7b69-49a5-c549-d5c7371b0be3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0                                   Should I Get Bings\n",
            "1        Which TV Female Friend Group Do You Belong In\n",
            "2    The New \"Star Wars: The Force Awakens\" Trailer...\n",
            "3    This Vine Of New York On \"Celebrity Big Brothe...\n",
            "4    A Couple Did A Stunning Photo Shoot With Their...\n",
            "Name: headline, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(X.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KW11ANizMqVK"
      },
      "source": [
        "Function to lowercase the words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Ulvn2ezrwSsL"
      },
      "outputs": [],
      "source": [
        "def lowercase(text):\n",
        "    return text.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "--bdlhA0wSsL"
      },
      "outputs": [],
      "source": [
        "X = X.apply(lowercase)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWES8fWGwSsM",
        "outputId": "fde48151-3b20-48b2-8170-615845082a29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0                                   should i get bings\n",
            "1        which tv female friend group do you belong in\n",
            "2    the new \"star wars: the force awakens\" trailer...\n",
            "3    this vine of new york on \"celebrity big brothe...\n",
            "4    a couple did a stunning photo shoot with their...\n",
            "Name: headline, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(X.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99v8-h5_NFAH"
      },
      "source": [
        "Tokenize or split the main string into an array of strings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TIxwpw8XwSsM"
      },
      "outputs": [],
      "source": [
        "def tokenization(words):\n",
        "    list_string =words.split()\n",
        "    return list_string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0OUL3EGcwSsM"
      },
      "outputs": [],
      "source": [
        "X = X.apply(tokenization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miEtdYdxwSsN",
        "outputId": "19d3fe20-a8ca-4e60-8db4-991957c434ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0                              [should, i, get, bings]\n",
            "1    [which, tv, female, friend, group, do, you, be...\n",
            "2    [the, new, \"star, wars:, the, force, awakens\",...\n",
            "3    [this, vine, of, new, york, on, \"celebrity, bi...\n",
            "4    [a, couple, did, a, stunning, photo, shoot, wi...\n",
            "Name: headline, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(X.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8K4rb8rND1w"
      },
      "source": [
        "Removing stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Es3dNTH1wSsN"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words(\"english\"))\n",
        "def remove_stopwords(words):\n",
        "    new_words=[]\n",
        "    for text in words:\n",
        "        if text not in stop_words:\n",
        "            new_words.append(text)\n",
        "    return new_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KoE8f9qCwSsN"
      },
      "outputs": [],
      "source": [
        "X = X.apply(remove_stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d55b0OrbwSsN",
        "outputId": "212334a8-dada-4726-f86f-bf61a3bf3511"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0                                         [get, bings]\n",
            "1                  [tv, female, friend, group, belong]\n",
            "2    [new, \"star, wars:, force, awakens\", trailer, ...\n",
            "3    [vine, new, york, \"celebrity, big, brother\", f...\n",
            "4    [couple, stunning, photo, shoot, baby, learnin...\n",
            "Name: headline, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(X.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNcfykl_NAdD"
      },
      "source": [
        "Remove punctuations on the words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "zCVYYkCYwSsO"
      },
      "outputs": [],
      "source": [
        "def remove_punctuation(words):\n",
        "    new_words = []\n",
        "    for text in words: \n",
        "        for punctuation in string.punctuation:\n",
        "            text = text.replace(punctuation, '')\n",
        "        new_words.append(text)\n",
        "    return new_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "emkyIQerwSsO"
      },
      "outputs": [],
      "source": [
        "X = X.apply(remove_punctuation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jj6L0wqmwSsO",
        "outputId": "32589ac8-4af0-4084-d8ee-972d79cb7647"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0                                         [get, bings]\n",
            "1                  [tv, female, friend, group, belong]\n",
            "2    [new, star, wars, force, awakens, trailer, giv...\n",
            "3    [vine, new, york, celebrity, big, brother, fuc...\n",
            "4    [couple, stunning, photo, shoot, baby, learnin...\n",
            "Name: headline, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(X.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tegi3Z31M9M9"
      },
      "source": [
        "Remove numbers and spaces on corresponding words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "bTEeTPo0wSsO"
      },
      "outputs": [],
      "source": [
        "def remove_numbers_and_spaces(words):\n",
        "    new_words = []\n",
        "    for text in words:\n",
        "        result = re.sub(r'\\d+', '', text)\n",
        "        result = re.sub(' +', ' ', result).strip()\n",
        "\n",
        "        if(result != \"\"):\n",
        "            new_words.append(result)\n",
        "    return new_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "mqlru-JSwSsO"
      },
      "outputs": [],
      "source": [
        "X = X.apply(remove_numbers_and_spaces)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUE6b0OLwSsP",
        "outputId": "65f40b9d-b52c-4bba-b070-c60c6dd9ea6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0                                         [get, bings]\n",
            "1                  [tv, female, friend, group, belong]\n",
            "2    [new, star, wars, force, awakens, trailer, giv...\n",
            "3    [vine, new, york, celebrity, big, brother, fuc...\n",
            "4    [couple, stunning, photo, shoot, baby, learnin...\n",
            "Name: headline, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(X.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-IZAMEGQinf"
      },
      "source": [
        "Split the X and y into train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "AlXisPtfwSsP"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXmVRzfEwSsP"
      },
      "source": [
        "Transforms each text in texts to a sequence of integers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "gOvle0ZZwSsQ"
      },
      "outputs": [],
      "source": [
        "vocab_size = 7500\n",
        "maxlen = 250\n",
        "embedding_size = 64\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(X)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JeZdq8IwSsQ",
        "outputId": "1a20c61e-113f-4862-ec0e-2eff529c0c62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[192, 209, 1216, 3167, 23, 819, 87, 373], [1016, 53, 3122, 6331, 6332, 4835, 710, 695, 1196], [33, 1011, 6979, 788, 243, 499, 99], [1419, 943, 1480, 126, 4146], [7383, 6737, 70, 33, 1354]]\n"
          ]
        }
      ],
      "source": [
        "print(X_train[0:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTwfBd14wSsR"
      },
      "source": [
        "Pads sequences to the same length so that the model will accept the same dimension of inputs everytime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "XMtFLcm2wSsR"
      },
      "outputs": [],
      "source": [
        "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, maxlen=maxlen)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yp3o2qRANNE_"
      },
      "source": [
        "<h1> 2. Architecture of the NLP Model </h1>\n",
        "<p>For the NLP Model i will be using LSTM, the reason for this is because they can recognize long-term connections in sequential data, which are frequently present in natural language texts, LSTMs are well suited for NLP applications. The meaning of a word frequently depends on the context of the words that come before and after it in this model. These kinds of activities are well suited for LSTMs because of their capacity to store information in memory cells for longer periods of time.<br><br>\n",
        "Layers :<br>\n",
        "1. Embedding layer: This layer takes as input the vocabulary size (vocab_size), the embedding size (embedding_size), and the maximum length of the input sequences (maxlen). It transforms the input data into a dense, lower-dimensional representation (embedding) of the input data.<br>\n",
        "2. LSTM layer: This layer is a Long Short-Term Memory (LSTM) layer with 64 units. It is used to capture the sequential relationships between the words in the input data.<br>\n",
        "3. Dense layer with ReLU activation: This is a fully connected dense layer with 64 units and a rectified linear unit (ReLU) activation function. It performs non-linear transformations on the output of the LSTM layer.<br>\n",
        "4. Dense layer with sigmoid activation: This is a fully connected dense layer with 1 unit and a sigmoid activation function. It outputs a probability or a binary classification result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMhHb8VBwSsR",
        "outputId": "6665badd-e9cf-4cff-ed24-4e4051077a46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 250, 64)           480000    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                33024     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 517,249\n",
            "Trainable params: 517,249\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_size, input_length=maxlen))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRqtcd5nwSsS",
        "outputId": "c293605a-65b1-4bc3-a392-a41c7ebe5563"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "50/50 [==============================] - 10s 83ms/step - loss: 0.5504 - accuracy: 0.8296 - val_loss: 0.2664 - val_accuracy: 0.9495\n",
            "Epoch 2/3\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1333 - accuracy: 0.9594 - val_loss: 0.1080 - val_accuracy: 0.9597\n",
            "Epoch 3/3\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0663 - accuracy: 0.9765 - val_loss: 0.1060 - val_accuracy: 0.9583\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(X_train, y_train, batch_size=512, validation_data=(X_test, y_test), epochs=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8WTuhpMPXWn"
      },
      "source": [
        "Make predictions using the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "EwzYiscxwSsS"
      },
      "outputs": [],
      "source": [
        "y_predictions = (model.predict(X_test) > 0.5)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oKbW8b40PcFV"
      },
      "source": [
        "<h1> 4a. Perfomance Analysis of the First Model</h1>\n",
        "\n",
        "<p>As we can see from the results of the LSTM NLP Model it has an accuracy of 95% from learning with a batch size of 512 on a 3 epochs run. These results are decent recalling from the metrics below. This architecture is well-suited for problems that involve sequential data and the capture of long-term dependencies. However, it may not be the best choice for problems that do not involve sequential data or where the relationships between elements are not important.</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bfEt6QKwSsS",
        "outputId": "a94f7f7e-2923-4914-b870-4c4e7b31cd89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1-score:  0.9590553596074222\n",
            "precision:  0.9519025875190259\n",
            "recall:  0.9663164400494437\n",
            "accuracy:  0.95828125\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.95      0.96      3164\n",
            "           1       0.95      0.97      0.96      3236\n",
            "\n",
            "    accuracy                           0.96      6400\n",
            "   macro avg       0.96      0.96      0.96      6400\n",
            "weighted avg       0.96      0.96      0.96      6400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"f1-score: \", f1_score(y_test, y_predictions))\n",
        "print(\"precision: \", precision_score(y_test, y_predictions))\n",
        "print(\"recall: \", recall_score(y_test, y_predictions))\n",
        "print(\"accuracy: \", accuracy_score(y_test, y_predictions))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91IuXnQUQan9"
      },
      "source": [
        "<h1> 3. Pre Trained NLP Model (Tensorflow BERT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "M07QT16OwSsS"
      },
      "outputs": [],
      "source": [
        "X = data['headline']\n",
        "y = data['clickbait']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "VA832aJKwSsS"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size= 0.20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8oKjnOEQn6X"
      },
      "source": [
        "Importing tensorflow hub and text to load the Bert Preprocessor and Bert Encoder before running the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "oZkGxMw4wSsS"
      },
      "outputs": [],
      "source": [
        "import tensorflow_hub as hub\n",
        "# !pip3 install --quiet \"tensorflow-text==2.8.*\"\n",
        "import tensorflow_text as text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "PWGKgpktwSsT"
      },
      "outputs": [],
      "source": [
        "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KG5igx2Quc3"
      },
      "source": [
        "Making of BERT Pre-Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "BsVGlSEewSsT"
      },
      "outputs": [],
      "source": [
        "text_input = Input(shape=(), dtype=tensorflow.string, name='text')\n",
        "preprocessed_text = bert_preprocess(text_input)\n",
        "outputs = bert_encoder(preprocessed_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "62yMF4qnwSsT"
      },
      "outputs": [],
      "source": [
        "l = Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
        "l = Dense(1, activation='sigmoid', name=\"output\")(l)\n",
        "model = Model(inputs=[text_input], outputs = [l])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lu1Zaex3wSsT",
        "outputId": "f1ffc2fe-5bac-482c-b62c-963621935a65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " keras_layer (KerasLayer)       {'input_type_ids':   0           ['text[0][0]']                   \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 128)}                                                          \n",
            "                                                                                                  \n",
            " keras_layer_1 (KerasLayer)     {'encoder_outputs':  109482241   ['keras_layer[0][0]',            \n",
            "                                 [(None, 128, 768),               'keras_layer[0][1]',            \n",
            "                                 (None, 128, 768),                'keras_layer[0][2]']            \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768)],                                               \n",
            "                                 'default': (None,                                                \n",
            "                                768),                                                             \n",
            "                                 'sequence_output':                                               \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 'pooled_output': (                                               \n",
            "                                None, 768)}                                                       \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 768)          0           ['keras_layer_1[0][13]']         \n",
            "                                                                                                  \n",
            " output (Dense)                 (None, 1)            769         ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,483,010\n",
            "Trainable params: 769\n",
            "Non-trainable params: 109,482,241\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "FH0u0cjYwSsT"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        " loss='binary_crossentropy',\n",
        " metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nc50kKsUQzkb"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qw-IiQbwSsU",
        "outputId": "92e8f3ff-b6ab-469e-fbf7-4185a4480b68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "50/50 [==============================] - 915s 18s/step - loss: 0.5183 - accuracy: 0.7448 - val_loss: 0.4169 - val_accuracy: 0.8266\n",
            "Epoch 2/3\n",
            "50/50 [==============================] - 816s 16s/step - loss: 0.3834 - accuracy: 0.8466 - val_loss: 0.3384 - val_accuracy: 0.8728\n",
            "Epoch 3/3\n",
            "50/50 [==============================] - 830s 17s/step - loss: 0.3284 - accuracy: 0.8757 - val_loss: 0.2947 - val_accuracy: 0.8950\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5f122bca90>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train, y_train, batch_size=512, validation_data=(X_test, y_test), epochs=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qn2e4r2XQ1OP"
      },
      "source": [
        "Make predictions using the BERT Model and classifying predictions values are within 0 and 1 (binary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "8QPA9Yk1wSsU"
      },
      "outputs": [],
      "source": [
        "y_predictions = model.predict(X_test)\n",
        "y_predictions = y_predictions.flatten()\n",
        "y_predictions = np.where(y_predictions > 0.5, 1, 0)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mOapVMO7Q83J"
      },
      "source": [
        "<h1> 4b. Perfomance Analysis of the Second Model (Pretrained BERT) </h1>\n",
        "\n",
        "<p>BERT uses a bidirectional representation of the input text, BERT takes into account both the left and right context of each word in the input sequence, while LSTMs only take into account the left context. This bidirectional representation allows BERT to capture more nuanced relationships between words in the input sequence. Therefore in the long run BERT Model is more superior than the first model. But the downside that BERT Model has a lot of parameters and takes a more time to train. Therefore for a specific/niche words to predict and train it is better to use a smaller model. <br><br>\n",
        "\n",
        "As for the results below are the metrics resulting also a good result within 512 batch size and 3 epochs. For a large parameters trained in BERT and considering the amount of dataset trained in BERT. A slightly lower accuracy of this doesn't mean that the first model is better, this results means that the BERT model is well fitted and the first model may be underfitted/overfitted. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KS_Fln0rwSsU",
        "outputId": "a711983c-2038-4c9d-c4bb-460e7832a324"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1-score:  0.8987951807228916\n",
            "precision:  0.8681990107652022\n",
            "recall:  0.9316266000624415\n",
            "accuracy:  0.895\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.86      0.89      3197\n",
            "           1       0.87      0.93      0.90      3203\n",
            "\n",
            "    accuracy                           0.90      6400\n",
            "   macro avg       0.90      0.89      0.89      6400\n",
            "weighted avg       0.90      0.90      0.89      6400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"f1-score: \", f1_score(y_test, y_predictions))\n",
        "print(\"precision: \", precision_score(y_test, y_predictions))\n",
        "print(\"recall: \", recall_score(y_test, y_predictions))\n",
        "print(\"accuracy: \", accuracy_score(y_test, y_predictions))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_predictions))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "810eadbe619ca2ad193fd0c1c00936df6e00d92fae6c19534e04fffbf3fb2f81"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
